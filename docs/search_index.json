[["Pandas0.html", "Chapter 13 Pandas : 快速入门 13.1 创建数据集 13.2 数据探查 13.3 排序 13.4 数据选取 13.5 新增列和赋值 13.6 缺失数据 13.7 数据运算 13.8 合并 13.9 分组聚合 13.10 重塑 13.11 时间序列 13.12 分类变量 13.13 作图 13.14 数据读写", " Chapter 13 Pandas : 快速入门 参考材料： https://pandas.pydata.org/docs/user_guide/10min.html https://www.gairuo.com/p/pandas-quick-start 13.1 创建数据集 先导入程序包： import numpy as np import pandas as pd pandas 和 NumPy 最本质的区别在于：NumPy 数组对整个数组只有一个 dtype，而 pandas 的 DataFrames 每列都有各自的 dtype。 s = pd.Series([1, 3, 5, np.nan, 6, 8]) # 创建Series s ## 0 1.0 ## 1 3.0 ## 2 5.0 ## 3 NaN ## 4 6.0 ## 5 8.0 ## dtype: float64 dates = pd.date_range(&quot;20220101&quot;, periods=6) # 创建Series dates ## DatetimeIndex([&#39;2022-01-01&#39;, &#39;2022-01-02&#39;, &#39;2022-01-03&#39;, &#39;2022-01-04&#39;, ## &#39;2022-01-05&#39;, &#39;2022-01-06&#39;], ## dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;) 可以通过提供Numpy数组，或者字典来创建DataFrame，每一列都是一个Series。 df = pd.DataFrame(np.random.randint(0,100,size = [6,4]), index=dates, columns=list(&quot;ABCD&quot;)) # 创建DataFrame s1 = pd.Series(list(range(6)), index=pd.date_range(&quot;20220101&quot;, periods=6)) # 创建Series df[&quot;A&quot;] = s1 df ## A B C D ## 2022-01-01 0 75 32 51 ## 2022-01-02 1 6 3 3 ## 2022-01-03 2 40 65 22 ## 2022-01-04 3 85 27 32 ## 2022-01-05 4 60 27 64 ## 2022-01-06 5 64 71 89 df2 = pd.DataFrame( { &quot;A&quot;: list(range(6)), &quot;B&quot;: &quot;foo&quot;, &quot;C&quot;: pd.Series(np.linspace(10, 100, 6), index=list(range(6))), &quot;D&quot;: np.random.randn(6)*10, &quot;E&quot;: pd.Categorical([&quot;test&quot;, &quot;train&quot;, &quot;test&quot;, &quot;train&quot;, &quot;test&quot;, &quot;train&quot;], categories= [&quot;test&quot;, &quot;train&quot;]), &quot;F&quot;: np.random.randint(1,10,6), &quot;T&quot;: pd.date_range(&quot;20220101&quot;, periods=6) } ) df2.set_index(&#39;T&#39;, inplace=True) # 建立索引并生效 df2 ## A B C D E F ## T ## 2022-01-01 0 foo 10.0 -3.137736 test 7 ## 2022-01-02 1 foo 28.0 -9.922927 train 8 ## 2022-01-03 2 foo 46.0 -3.465670 test 1 ## 2022-01-04 3 foo 64.0 -10.373631 train 2 ## 2022-01-05 4 foo 82.0 8.530883 test 2 ## 2022-01-06 5 foo 100.0 -16.991555 train 7 13.2 数据探查 df.dtypes # 查看各字段类型 ## A int64 ## B int32 ## C int32 ## D int32 ## dtype: object df.shape # 查看形状：行数和列数 ## (6, 4) df.axes # 显示数据行和列名 ## [DatetimeIndex([&#39;2022-01-01&#39;, &#39;2022-01-02&#39;, &#39;2022-01-03&#39;, &#39;2022-01-04&#39;, ## &#39;2022-01-05&#39;, &#39;2022-01-06&#39;], ## dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;), Index([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;], dtype=&#39;object&#39;)] df.index # 查看索引列/行名 ## DatetimeIndex([&#39;2022-01-01&#39;, &#39;2022-01-02&#39;, &#39;2022-01-03&#39;, &#39;2022-01-04&#39;, ## &#39;2022-01-05&#39;, &#39;2022-01-06&#39;], ## dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;) df.columns # 列名 ## Index([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;], dtype=&#39;object&#39;) 数据整体信息统计： df.info() # 查看数据类型、索引情况、行列数、各字段数据类型、内存占用等 ## &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; ## DatetimeIndex: 6 entries, 2022-01-01 to 2022-01-06 ## Freq: D ## Data columns (total 4 columns): ## # Column Non-Null Count Dtype ## --- ------ -------------- ----- ## 0 A 6 non-null int64 ## 1 B 6 non-null int32 ## 2 C 6 non-null int32 ## 3 D 6 non-null int32 ## dtypes: int32(3), int64(1) ## memory usage: 168.0 bytes df.describe() # 查看各数字字段的总数、平均数、标准差、最大最小值和四分位数 ## A B C D ## count 6.000000 6.000000 6.000000 6.000000 ## mean 2.500000 55.000000 37.500000 43.500000 ## std 1.870829 28.397183 25.766257 30.924101 ## min 0.000000 6.000000 3.000000 3.000000 ## 25% 1.250000 45.000000 27.000000 24.500000 ## 50% 2.500000 62.000000 29.500000 41.500000 ## 75% 3.750000 72.250000 56.750000 60.750000 ## max 5.000000 85.000000 71.000000 89.000000 数据抽样查看： n = 5 df.head(n) # 查看 DataFrame 对象的前n行 ## A B C D ## 2022-01-01 0 75 32 51 ## 2022-01-02 1 6 3 3 ## 2022-01-03 2 40 65 22 ## 2022-01-04 3 85 27 32 ## 2022-01-05 4 60 27 64 df.tail(n) # 查看 DataFrame 对象的最后n行 ## A B C D ## 2022-01-02 1 6 3 3 ## 2022-01-03 2 40 65 22 ## 2022-01-04 3 85 27 32 ## 2022-01-05 4 60 27 64 ## 2022-01-06 5 64 71 89 df.sample(n) # 查看 n 个样本，随机 ## A B C D ## 2022-01-01 0 75 32 51 ## 2022-01-02 1 6 3 3 ## 2022-01-04 3 85 27 32 ## 2022-01-05 4 60 27 64 ## 2022-01-03 2 40 65 22 13.3 排序 按索引列排序： df.sort_index(axis=1, ascending=False) ## D C B A ## 2022-01-01 51 32 75 0 ## 2022-01-02 3 3 6 1 ## 2022-01-03 22 65 40 2 ## 2022-01-04 32 27 85 3 ## 2022-01-05 64 27 60 4 ## 2022-01-06 89 71 64 5 按列的取值排序： df.sort_values(by=&quot;D&quot;) ## A B C D ## 2022-01-02 1 6 3 3 ## 2022-01-03 2 40 65 22 ## 2022-01-04 3 85 27 32 ## 2022-01-01 0 75 32 51 ## 2022-01-05 4 60 27 64 ## 2022-01-06 5 64 71 89 13.4 数据选取 选取列： df[&quot;A&quot;] ## 2022-01-01 0 ## 2022-01-02 1 ## 2022-01-03 2 ## 2022-01-04 3 ## 2022-01-05 4 ## 2022-01-06 5 ## Freq: D, Name: A, dtype: int64 选择多列： df[[&quot;A&quot;, &quot;B&quot;]] ## A B ## 2022-01-01 0 75 ## 2022-01-02 1 6 ## 2022-01-03 2 40 ## 2022-01-04 3 85 ## 2022-01-05 4 60 ## 2022-01-06 5 64 df.loc[:, [&quot;A&quot;, &quot;B&quot;]] ## A B ## 2022-01-01 0 75 ## 2022-01-02 1 6 ## 2022-01-03 2 40 ## 2022-01-04 3 85 ## 2022-01-05 4 60 ## 2022-01-06 5 64 df.loc[x, y] 是一个非常强大的数据选择函数，其中 x 代表行，y 代表列，行和列都支持条件表达式，也支持类似列表那样的切片（如果要用自然索引需要用 df.iloc[]）。 df.iloc[:, 1:3] #筛选第2-3列 ## B C ## 2022-01-01 75 32 ## 2022-01-02 6 3 ## 2022-01-03 40 65 ## 2022-01-04 85 27 ## 2022-01-05 60 27 ## 2022-01-06 64 71 选取行： # 用人工索引选取 df[df.index == &#39;2022-01-02&#39;] # 指定索引 # 用自然索引选择，类似列表的切片 ## A B C D ## 2022-01-02 1 6 3 3 df[0:3] # 取前三行, ## A B C D ## 2022-01-01 0 75 32 51 ## 2022-01-02 1 6 3 3 ## 2022-01-03 2 40 65 22 df[0:10:2] # 前10行，每两行取一行 ## A B C D ## 2022-01-01 0 75 32 51 ## 2022-01-03 2 40 65 22 ## 2022-01-05 4 60 27 64 df.iloc[:10,:] # 前10行 ## A B C D ## 2022-01-01 0 75 32 51 ## 2022-01-02 1 6 3 3 ## 2022-01-03 2 40 65 22 ## 2022-01-04 3 85 27 32 ## 2022-01-05 4 60 27 64 ## 2022-01-06 5 64 71 89 指定行列： df.loc[&#39;2022-01-02&#39;, &#39;A&#39;:&#39;C&#39;] # 指定列区间 ## A 1 ## B 6 ## C 3 ## Name: 2022-01-02 00:00:00, dtype: int64 df.loc[&#39;2022-01-02&#39;:&#39;2022-01-04&#39;, &#39;A&#39;:&#39;C&#39;] # 指定行区间 ## A B C ## 2022-01-02 1 6 3 ## 2022-01-03 2 40 65 ## 2022-01-04 3 85 27 条件选择： # 单一条件 df[df.A &gt;= 10] ## Empty DataFrame ## Columns: [A, B, C, D] ## Index: [] df[df.A == 5] ## A B C D ## 2022-01-06 5 64 71 89 df[df.index == &#39;2022-01-02&#39;] ## A B C D ## 2022-01-02 1 6 3 3 df[df[&#39;A&#39;].isin([0,4])] # 组合条件 ## A B C D ## 2022-01-01 0 75 32 51 ## 2022-01-05 4 60 27 64 df[(df[&#39;A&#39;] &gt;= 2) &amp; (df[&#39;B&#39;] &gt; 10)] # and 关系 ## A B C D ## 2022-01-03 2 40 65 22 ## 2022-01-04 3 85 27 32 ## 2022-01-05 4 60 27 64 ## 2022-01-06 5 64 71 89 df[df[&#39;B&#39;] &gt; 10].loc[df.A &gt;= 2] # 多重筛选 ## A B C D ## 2022-01-03 2 40 65 22 ## 2022-01-04 3 85 27 32 ## 2022-01-05 4 60 27 64 ## 2022-01-06 5 64 71 89 13.5 新增列和赋值 设置新列会自动按索引对齐数据。 s1 = pd.Series(np.random.randn(6)*20, index=pd.date_range(&quot;20220102&quot;, periods=6)) s1 ## 2022-01-02 22.515078 ## 2022-01-03 -6.296330 ## 2022-01-04 20.723444 ## 2022-01-05 -41.020925 ## 2022-01-06 -15.611778 ## 2022-01-07 1.745822 ## Freq: D, dtype: float64 df[&quot;G&quot;] = s1 df ## A B C D G ## 2022-01-01 0 75 32 51 NaN ## 2022-01-02 1 6 3 3 22.515078 ## 2022-01-03 2 40 65 22 -6.296330 ## 2022-01-04 3 85 27 32 20.723444 ## 2022-01-05 4 60 27 64 -41.020925 ## 2022-01-06 5 64 71 89 -15.611778 df.iat[0, 1] = 0 # Setting values by position df.loc[:, &quot;G&quot;] = np.array([5] * len(df)) # Setting values by column df ## A B C D G ## 2022-01-01 0 0 32 51 5 ## 2022-01-02 1 6 3 3 5 ## 2022-01-03 2 40 65 22 5 ## 2022-01-04 3 85 27 32 5 ## 2022-01-05 4 60 27 64 5 ## 2022-01-06 5 64 71 89 5 13.6 缺失数据 pandas 主要使用值 np.nan 来表示缺失数据。默认情况下，它会在计算中被排除。 dates = pd.date_range(&quot;20220101&quot;, periods=6) df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [&quot;E&quot;]) df1.loc[dates[0] : dates[1], &quot;E&quot;] = 1 df1 ## A B C D G E ## 2022-01-01 0 0 32 51 5 1.0 ## 2022-01-02 1 6 3 3 5 1.0 ## 2022-01-03 2 40 65 22 5 NaN ## 2022-01-04 3 85 27 32 5 NaN 删除任何有缺失数据的行。 df1.dropna(how=&quot;any&quot;) ## A B C D G E ## 2022-01-01 0 0 32 51 5 1.0 ## 2022-01-02 1 6 3 3 5 1.0 填充缺失数据。 df1.fillna(value=5) ## A B C D G E ## 2022-01-01 0 0 32 51 5 1.0 ## 2022-01-02 1 6 3 3 5 1.0 ## 2022-01-03 2 40 65 22 5 5.0 ## 2022-01-04 3 85 27 32 5 5.0 获取值为 nan 的布尔掩码。 pd.isna(df1) ## A B C D G E ## 2022-01-01 False False False False False False ## 2022-01-02 False False False False False False ## 2022-01-03 False False False False False True ## 2022-01-04 False False False False False True 13.7 数据运算 13.7.1 Stats df.mean() # 返回所有列的均值 ## A 2.5 ## B 42.5 ## C 37.5 ## D 43.5 ## G 5.0 ## dtype: float64 df.mean(1) # 返回所有行的均值，下同 ## 2022-01-01 17.6 ## 2022-01-02 3.6 ## 2022-01-03 26.8 ## 2022-01-04 30.4 ## 2022-01-05 32.0 ## 2022-01-06 46.8 ## Freq: D, dtype: float64 df.corr() # 返回列与列之间的相关系数 ## A B C D G ## A 1.000000 0.832880 0.475062 0.662015 NaN ## B 0.832880 1.000000 0.347579 0.394205 NaN ## C 0.475062 0.347579 1.000000 0.550829 NaN ## D 0.662015 0.394205 0.550829 1.000000 NaN ## G NaN NaN NaN NaN NaN df.count() # 返回每一列中的非空值的个数 ## A 6 ## B 6 ## C 6 ## D 6 ## G 6 ## dtype: int64 df.max() # 返回每一列的最大值 ## A 5 ## B 85 ## C 71 ## D 89 ## G 5 ## dtype: int64 df.min() # 返回每一列的最小值 ## A 0 ## B 0 ## C 3 ## D 3 ## G 5 ## dtype: int64 df.median() # 返回每一列的中位数 ## A 2.5 ## B 50.0 ## C 29.5 ## D 41.5 ## G 5.0 ## dtype: float64 df.std() # 返回每一列的标准差 ## A 1.870829 ## B 33.821591 ## C 25.766257 ## D 30.924101 ## G 0.000000 ## dtype: float64 df.var() # 方差 ## A 3.5 ## B 1143.9 ## C 663.9 ## D 956.3 ## G 0.0 ## dtype: float64 13.7.2 Apply df1 = df.drop(&quot;G&quot;, axis = 1) #删除列 df1.apply(np.cumsum) ## A B C D ## 2022-01-01 0 0 32 51 ## 2022-01-02 1 6 35 54 ## 2022-01-03 3 46 100 76 ## 2022-01-04 6 131 127 108 ## 2022-01-05 10 191 154 172 ## 2022-01-06 15 255 225 261 df1.apply(lambda x: x.max() - x.min()) ## A 5 ## B 85 ## C 68 ## D 86 ## dtype: int64 13.8 合并 详细介绍参考：Merge, join, concatenate and compare。 13.8.1 Concat pandas 提供了各种拼接/合并操作的工具，可以将 Series 和 DataFrame 对象通过索引各种集合逻辑运算，以及关系代数功能组合在一起。 df = pd.DataFrame(np.random.randn(10, 4)) df # break it into pieces ## 0 1 2 3 ## 0 -0.227845 0.308342 -0.288489 0.330470 ## 1 0.160244 -0.841805 1.311695 -1.902229 ## 2 -1.032769 0.974797 0.484686 -1.292676 ## 3 -0.162943 -0.570515 -0.125162 -0.420704 ## 4 -0.408247 -1.115998 0.331252 0.104708 ## 5 -1.263116 0.428984 0.895596 0.696729 ## 6 -0.119355 -0.568801 0.326075 -0.602433 ## 7 -0.044152 -0.183331 -0.597011 -0.099038 ## 8 0.809572 1.651221 -0.362867 1.489753 ## 9 0.141824 -0.416347 0.483541 0.591489 pieces = [df[:3], df[3:7], df[7:]] pd.concat(pieces) ## 0 1 2 3 ## 0 -0.227845 0.308342 -0.288489 0.330470 ## 1 0.160244 -0.841805 1.311695 -1.902229 ## 2 -1.032769 0.974797 0.484686 -1.292676 ## 3 -0.162943 -0.570515 -0.125162 -0.420704 ## 4 -0.408247 -1.115998 0.331252 0.104708 ## 5 -1.263116 0.428984 0.895596 0.696729 ## 6 -0.119355 -0.568801 0.326075 -0.602433 ## 7 -0.044152 -0.183331 -0.597011 -0.099038 ## 8 0.809572 1.651221 -0.362867 1.489753 ## 9 0.141824 -0.416347 0.483541 0.591489 13.8.2 Join pandas 提供了一个函数merge()，作为 DataFrame 或命名 Series 对象之间所有标准数据库join操作的入口： left = pd.DataFrame({&quot;key&quot;: [&quot;foo&quot;, &quot;foo&quot;], &quot;lval&quot;: [1, 2]}) left ## key lval ## 0 foo 1 ## 1 foo 2 right = pd.DataFrame({&quot;key&quot;: [&quot;foo&quot;, &quot;foo&quot;], &quot;rval&quot;: [4, 5]}) right ## key rval ## 0 foo 4 ## 1 foo 5 pd.merge(left, right, on=&quot;key&quot;) ## key lval rval ## 0 foo 1 4 ## 1 foo 1 5 ## 2 foo 2 4 ## 3 foo 2 5 13.9 分组聚合 详细介绍参考：Grouping section. 分组聚合包含以下三步： - Splitting the data into groups based on some criteria - Applying a function to each group independently - Combining the results into a data structure df = pd.DataFrame( { &quot;A&quot;: [&quot;foo&quot;, &quot;bar&quot;, &quot;foo&quot;, &quot;bar&quot;, &quot;foo&quot;, &quot;bar&quot;, &quot;foo&quot;, &quot;foo&quot;], &quot;B&quot;: [&quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;two&quot;, &quot;two&quot;, &quot;one&quot;, &quot;three&quot;], &quot;C&quot;: np.random.randn(8), &quot;D&quot;: np.random.randn(8), } ) df ## A B C D ## 0 foo one -0.919380 -0.230649 ## 1 bar one -0.936290 0.155742 ## 2 foo two -0.964434 0.708018 ## 3 bar three 0.162207 1.758965 ## 4 foo two -0.490138 1.739501 ## 5 bar two 0.975717 0.714773 ## 6 foo one 0.802047 -0.226642 ## 7 foo three 1.151327 -0.112447 df.groupby(&quot;A&quot;).sum() ## C D ## A ## bar 0.201634 2.629479 ## foo -0.420577 1.877780 df.groupby([&quot;A&quot;, &quot;B&quot;]).sum() ## C D ## A B ## bar one -0.936290 0.155742 ## three 0.162207 1.758965 ## two 0.975717 0.714773 ## foo one -0.117333 -0.457291 ## three 1.151327 -0.112447 ## two -1.454572 2.447519 13.10 重塑 13.10.1 Stack tuples = list( zip( *[ [&quot;bar&quot;, &quot;bar&quot;, &quot;baz&quot;, &quot;baz&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;qux&quot;, &quot;qux&quot;], [&quot;one&quot;, &quot;two&quot;, &quot;one&quot;, &quot;two&quot;, &quot;one&quot;, &quot;two&quot;, &quot;one&quot;, &quot;two&quot;], ] ) ) index = pd.MultiIndex.from_tuples(tuples, names=[&quot;first&quot;, &quot;second&quot;]) df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=[&quot;A&quot;, &quot;B&quot;]) df2 = df[:4] df2 ## A B ## first second ## bar one -0.020706 1.419281 ## two 0.746680 -0.474683 ## baz one -0.119277 -0.818116 ## two -0.077438 -1.361648 stack() 方法在 DataFrame 中压缩一个列。 stacked = df2.stack() stacked ## first second ## bar one A -0.020706 ## B 1.419281 ## two A 0.746680 ## B -0.474683 ## baz one A -0.119277 ## B -0.818116 ## two A -0.077438 ## B -1.361648 ## dtype: float64 stacked.unstack() ## A B ## first second ## bar one -0.020706 1.419281 ## two 0.746680 -0.474683 ## baz one -0.119277 -0.818116 ## two -0.077438 -1.361648 13.10.2 数据透视表（Pivot Table） df = pd.DataFrame( { &quot;A&quot;: [&quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;three&quot;] * 3, &quot;B&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;] * 4, &quot;C&quot;: [&quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;bar&quot;, &quot;bar&quot;, &quot;bar&quot;] * 2, &quot;D&quot;: np.random.randn(12), &quot;E&quot;: np.random.randn(12), } ) df ## A B C D E ## 0 one A foo -1.679263 0.268747 ## 1 one B foo 1.841385 1.008743 ## 2 two C foo 1.499848 1.679960 ## 3 three A bar -0.730837 0.627331 ## 4 one B bar -0.648378 -0.934658 ## 5 one C bar -0.268871 -0.201840 ## 6 two A foo -1.721658 -0.351682 ## 7 three B foo -0.200341 0.479305 ## 8 one C foo 0.389757 -0.137032 ## 9 one A bar -0.755993 0.280494 ## 10 two B bar 0.309239 0.668060 ## 11 three C bar 1.900081 0.618124 pd.pivot_table(df, values=&quot;D&quot;, index=[&quot;A&quot;, &quot;B&quot;], columns=[&quot;C&quot;]) ## C bar foo ## A B ## one A -0.755993 -1.679263 ## B -0.648378 1.841385 ## C -0.268871 0.389757 ## three A -0.730837 NaN ## B NaN -0.200341 ## C 1.900081 NaN ## two A NaN -1.721658 ## B 0.309239 NaN ## C NaN 1.499848 13.11 时间序列 pandas 具有简单、强大、高效的在变频期间进行重采样操作的功能。 rng = pd.date_range(&quot;1/1/2012&quot;, periods=100, freq=&quot;S&quot;) ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng) ts.resample(&quot;5Min&quot;).sum() ## 2012-01-01 22985 ## Freq: 5T, dtype: int32 rng = pd.date_range(&quot;3/6/2012 00:00&quot;, periods=5, freq=&quot;D&quot;) ts = pd.Series(np.random.randn(len(rng)), rng) ts ## 2012-03-06 -1.688388 ## 2012-03-07 -0.831431 ## 2012-03-08 0.899717 ## 2012-03-09 0.527414 ## 2012-03-10 -0.299368 ## Freq: D, dtype: float64 ts_utc = ts.tz_localize(&quot;UTC&quot;) ts_utc ## 2012-03-06 00:00:00+00:00 -1.688388 ## 2012-03-07 00:00:00+00:00 -0.831431 ## 2012-03-08 00:00:00+00:00 0.899717 ## 2012-03-09 00:00:00+00:00 0.527414 ## 2012-03-10 00:00:00+00:00 -0.299368 ## Freq: D, dtype: float64 在时间跨度表示之间转换： rng = pd.date_range(&quot;1/1/2012&quot;, periods=5, freq=&quot;M&quot;) ts = pd.Series(np.random.randn(len(rng)), index=rng) ts ## 2012-01-31 0.197241 ## 2012-02-29 0.479163 ## 2012-03-31 1.000009 ## 2012-04-30 -0.171820 ## 2012-05-31 0.757025 ## Freq: M, dtype: float64 ps = ts.to_period() ps ## 2012-01 0.197241 ## 2012-02 0.479163 ## 2012-03 1.000009 ## 2012-04 -0.171820 ## 2012-05 0.757025 ## Freq: M, dtype: float64 ps.to_timestamp() ## 2012-01-01 0.197241 ## 2012-02-01 0.479163 ## 2012-03-01 1.000009 ## 2012-04-01 -0.171820 ## 2012-05-01 0.757025 ## Freq: MS, dtype: float64 13.12 分类变量 df = pd.DataFrame( {&quot;id&quot;: [1, 2, 3, 4, 5, 6], &quot;raw_grade&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;e&quot;]} ) df[&quot;grade&quot;] = df[&quot;raw_grade&quot;].astype(&quot;category&quot;) df[&quot;grade&quot;] ## 0 a ## 1 b ## 2 b ## 3 a ## 4 a ## 5 e ## Name: grade, dtype: category ## Categories (3, object): [&#39;a&#39;, &#39;b&#39;, &#39;e&#39;] # Rename the categories to more meaningful names df[&quot;grade&quot;].cat.categories = [&quot;very good&quot;, &quot;good&quot;, &quot;very bad&quot;] # Reorder the categories and simultaneously add the missing categories df[&quot;grade&quot;] = df[&quot;grade&quot;].cat.set_categories( [&quot;very bad&quot;, &quot;bad&quot;, &quot;medium&quot;, &quot;good&quot;, &quot;very good&quot;] ) df[&quot;grade&quot;] ## 0 very good ## 1 good ## 2 good ## 3 very good ## 4 very good ## 5 very bad ## Name: grade, dtype: category ## Categories (5, object): [&#39;very bad&#39;, &#39;bad&#39;, &#39;medium&#39;, &#39;good&#39;, &#39;very good&#39;] df.sort_values(by=&quot;grade&quot;) ## id raw_grade grade ## 5 6 e very bad ## 1 2 b good ## 2 3 b good ## 0 1 a very good ## 3 4 a very good ## 4 5 a very good df.groupby(&quot;grade&quot;).size() ## grade ## very bad 1 ## bad 0 ## medium 0 ## good 2 ## very good 3 ## dtype: int64 13.13 作图 import matplotlib.pyplot as plt ts = pd.Series(np.random.randn(1000), index=pd.date_range(&quot;1/1/2000&quot;, periods=1000)) ts = ts.cumsum() ts.plot() df = pd.DataFrame( np.random.randn(1000, 4), index=ts.index, columns=[&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;] ) df = df.cumsum() plt.figure() df.plot() plt.legend(loc=&#39;best&#39;) 13.14 数据读写 使用 read_* 函数读取数据： import pandas as pd titanic = pd.read_csv(&quot;data/titanic.csv&quot;) titanic.head(6) ## PassengerId Survived Pclass ... Fare Cabin Embarked ## 0 1 0 3 ... 7.2500 NaN S ## 1 2 1 1 ... 71.2833 C85 C ## 2 3 1 3 ... 7.9250 NaN S ## 3 4 1 1 ... 53.1000 C123 S ## 4 5 0 3 ... 8.0500 NaN S ## 5 6 0 3 ... 8.4583 NaN Q ## ## [6 rows x 12 columns] 可以选择要读取的列： titanic = pd.read_table(&#39;data/titanic.txt&#39;, usecols=[&#39;PassengerId&#39;,&#39;Survived&#39;,&#39;Pclass&#39;, &#39;Sex&#39;,&#39;Age&#39;]) 从其他文件格式读取： titanic = pd.read_excel(&quot;data/titanic.xlsx&quot;) titanic = pd.read_table(&#39;data/titanic.txt&#39;, sep=&#39;\\t&#39;) titanic.dtypes ## PassengerId int64 ## Survived int64 ## Pclass int64 ## Sex object ## Age float64 ## dtype: object titanic.info() ## &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; ## RangeIndex: 891 entries, 0 to 890 ## Data columns (total 5 columns): ## # Column Non-Null Count Dtype ## --- ------ -------------- ----- ## 0 PassengerId 891 non-null int64 ## 1 Survived 891 non-null int64 ## 2 Pclass 891 non-null int64 ## 3 Sex 891 non-null object ## 4 Age 714 non-null float64 ## dtypes: float64(1), int64(3), object(1) ## memory usage: 34.9+ KB 使用 to_* 方法导出数据： titanic.to_excel(&quot;data/titanic.xlsx&quot;, index=False) titanic.to_csv(&#39;data/titanic.txt&#39;, sep=&#39;\\t&#39;, index=False) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
